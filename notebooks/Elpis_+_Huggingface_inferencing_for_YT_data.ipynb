{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm0bAolOfVjF"
      },
      "source": [
        "# Elpis + Huggingface inferencing\n",
        "\n",
        "This notebook provides two methods to infer audio using models published on Huggingface hub. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwYQvagedQ_6"
      },
      "source": [
        "1) First up, install the packages we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3532TyOvORn4"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install tqdm\n",
        "!pip install json-to-elan\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XGkBWX2dUNx"
      },
      "source": [
        "2) Next, import them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M2C-blyLgu1"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import json\n",
        "import string\n",
        "import gdown\n",
        "from transformers import pipeline\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "from json_to_elan import make_elan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ3Xcu4sdrmH"
      },
      "source": [
        "3) Specify the model that you want to use to infer with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eoVOxzSdm8H"
      },
      "outputs": [],
      "source": [
        "model_name = \"FYTM_fb_GUN\"\n",
        "my_model = f\"elpis/{model_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wzbu3QldwHy"
      },
      "source": [
        "4) This code creates the pipeline. The `access_token` is required for private models. The access token must be from the account which published the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uUuOEY3Mk9T"
      },
      "outputs": [],
      "source": [
        "access_token = \"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\"\n",
        "pipe = pipeline(\"automatic-speech-recognition\", model=my_model, use_auth_token=access_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgfzO07QNL9H"
      },
      "source": [
        "5) Let's put the infer code into a function for simpler repetition. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC3OiYZZV6Xv"
      },
      "outputs": [],
      "source": [
        "# Build some directories\n",
        "working_dir = Path(\"/content\")\n",
        "audio_dir_path = working_dir / \"audio\"\n",
        "\n",
        "inf_dir_path = working_dir / \"drive/MyDrive/Zara/inf_test\"\n",
        "\n",
        "audio_dir_path.mkdir(parents=True, exist_ok=True)\n",
        "inf_dir_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Eq2S9_xOT3C"
      },
      "outputs": [],
      "source": [
        "def infer_me(audio_file_path:Path=None, inf_dir_path:Path=None, inf_name:str=\"\"):\n",
        "\n",
        "    #  Get the inference\n",
        "    infer = pipe(f\"{audio_file_path}\", chunk_length_s=10, return_timestamps=\"word\")\n",
        "\n",
        "    # Write the inference text to a file\n",
        "    inf_text_file_path = inf_dir_path / f\"{inf_name}_inf.txt\"\n",
        "    with open(inf_text_file_path, \"w\") as infer_text_file:\n",
        "        infer_text_file.write(str.lower(infer[\"text\"]))\n",
        "    \n",
        "    # Write the data to JSON file for later conversion to Elan format\n",
        "    inf_json_file_path = inf_dir_path / f\"{inf_name}_inf.json\"\n",
        "    with open(inf_json_file_path, \"w\") as infer_json_file:\n",
        "        json.dump(infer[\"chunks\"], infer_json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1VieD1tXJ0N"
      },
      "source": [
        "## Download and process files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gERfiMvhgEj5"
      },
      "outputs": [],
      "source": [
        "# Mount your Google Drive. Can be handy for moving results around...\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvTvDNTLNGFu"
      },
      "outputs": [],
      "source": [
        "\n",
        "source_files = [\n",
        "    [\"1X83crFz0yEc5_AKgDTsjjc-vltf1HrlY\", \"ZMS_EIP_010_Pronoun.wav\"],\n",
        "    # [\"1ugkbrI3Yfqzs_1gvhZxRZwhm3Zq9vPJP\", \"ZMS_EIP_011_Millions.wav\"],\n",
        "    # [\"1RtmZi_zg4WfB8ViVvRZIvWMh_8b5D9mN\", \"ZMS_EIP_013_Transaction.wav\"],\n",
        "    # [\"1SzPct1m5a1O7LANAuZ2APJW5PlbsXdXe\", \"ZMS_GUN_004_Vocab4001.wav\"],\n",
        "    # [\"1lIVSesIWngp_rMHy4UFVtRUB8lYqgUHP\", \"ZMS_GUN_004_Vocab4010.wav\"],\n",
        "    # [\"1YxrJt0G5gjA03TWHWbl5-9_xbKLcSQSZ\", \"ZMS_JER_019_FIWS2-6.wav\"],\n",
        "    # [\"1B7tNM5pr2qnmHA5qbmezXg3Rg0gzRowX\", \"ZMS_JER_079_M-GrammarFartsID.wav\"],\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_W0ORtyN3WW"
      },
      "outputs": [],
      "source": [
        "# Use this to test a single file\n",
        "# source_files = [\n",
        "#     [\"1X83crFz0yEc5_AKgDTsjjc-vltf1HrlY\", \"ZMS_EIP_010_Pronoun.wav\"],\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baQ8FsRvReT_"
      },
      "outputs": [],
      "source": [
        "# Download each audio file and save them in the content dir\n",
        "for source_file in source_files:\n",
        "    audio_file_path = audio_dir_path / source_file[1]\n",
        "    gdown.download(id=source_file[0], output=audio_file_path.as_posix(), quiet=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKGVEi7ok6_N"
      },
      "outputs": [],
      "source": [
        "for source_file in source_files:\n",
        "    audio_file_path = audio_dir_path / source_file[1]\n",
        "    name_stem = audio_file_path.stem\n",
        "    inf_file_name = f\"{name_stem}_{model_name}\"\n",
        "    audio_file_path = audio_dir_path / source_file[1]\n",
        "    infer_me(audio_file_path=audio_file_path, inf_dir_path=inf_dir_path, inf_name=inf_file_name)\n",
        "    print(f\"{source_file[1]} done \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxMuLlIyH7xt"
      },
      "source": [
        "Build Elan files from the JSON files in the dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqI3L5yaH5o8"
      },
      "outputs": [],
      "source": [
        "make_elan(data_dir=\"/content/inf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiUJJqa61EtW"
      },
      "source": [
        "Copy the files to Google Drive for use in other notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip-lUvXrjAuH"
      },
      "outputs": [],
      "source": [
        "!cp /content/inf/* /content/drive/MyDrive/Zara/eaf_ref_inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYa4xDj9jn7W"
      },
      "outputs": [],
      "source": [
        "!cp /content/audio/* /content/drive/MyDrive/Zara/eaf_ref_inf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then you might like to upload Elan ref files to that `eaf_ref_inf` folder and run this notebook which aligns inference words to reference utterances based on the timing info.\n",
        "\n",
        "https://colab.research.google.com/drive/1bQZn318tUGSTujWON5moqlvaoyuohUas?usp=sharing"
      ],
      "metadata": {
        "id": "2xnyXlm84liu"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}